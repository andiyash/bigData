{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d881463-22b9-4cb2-856c-653ef484729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf \n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql as sql\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be967db-1995-4d25-b6a8-66b2c1667b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://n1.maapr.xyz:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2.0-eep-800</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    sc.setLogLevel(\"ERROR\")  \n",
    "except:\n",
    "    conf = SparkConf().setAppName(\"Lab1\").setMaster('local[1]')\n",
    "    sc = SparkContext(conf=conf)\n",
    "    sc.setLogLevel(\"ERROR\")  \n",
    "spark = SparkSession(sc)\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1702343-d058-49fa-83b7-3b2566e0ae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `list_of_countries_sorted_gini.txt': File exists\n",
      "put: `nyctaxi.csv': File exists\n",
      "put: `programming-languages.csv': File exists\n",
      "put: `stations.csv': File exists\n",
      "put: `trips.csv': File exists\n",
      "put: `Untitled.ipynb': File exists\n",
      "put: `warandsociety.txt': File exists\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -put * ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09279acc-12d8-46f7-b20f-33bc02973650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwxr-xr-x   - andiyash andiyash          1 2023-12-22 20:58 .sparkStaging\n",
      "-rwxr-xr-x   3 andiyash andiyash       1318 2023-12-22 15:51 Untitled.ipynb\n",
      "drwxr-xr-x   - andiyash andiyash          6 2023-12-22 15:51 data\n",
      "-rwxr-xr-x   3 andiyash andiyash        394 2023-12-22 15:51 list_of_countries_sorted_gini.txt\n",
      "-rwxr-xr-x   3 andiyash andiyash   79500408 2023-12-22 15:51 nyctaxi.csv\n",
      "-rwxr-xr-x   3 andiyash andiyash      40269 2023-12-22 15:51 programming-languages.csv\n",
      "-rwxr-xr-x   3 andiyash andiyash       5647 2023-12-22 15:51 stations.csv\n",
      "-rwxr-xr-x   3 andiyash andiyash   80208831 2023-12-22 16:54 trips.csv\n",
      "-rwxr-xr-x   3 andiyash andiyash    5315699 2023-12-22 00:46 warandsociety.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092e2f07-74cd-422d-a1e4-9f7d203ce939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, duration: int, start_date: timestamp, start_station_name: string, start_station_id: int, end_date: timestamp, end_station_name: string, end_station_id: int, bike_id: int, subscription_type: string, zip_code: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Чтение файлов (взял Ваш код)\n",
    "tripData = spark.read\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"inferSchema\", True)\\\n",
    ".option(\"timestampFormat\", 'M/d/y H:m')\\\n",
    ".csv(\"trips.csv\")\n",
    "\n",
    "tripData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016a7b75-db1a-4043-9d2e-892c95f61fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, name: string, lat: double, long: double, dock_count: int, city: string, installation_date: timestamp]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Чтение данных из файла \"stations.csv\" и создание DataFrame stationData\n",
    "stationData = spark.read\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"inferSchema\", True)\\\n",
    ".option(\"timestampFormat\", 'M/d/y')\\\n",
    ".csv(\"stations.csv\")\n",
    "\n",
    "stationData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052596ee-de0f-4587-b9e2-229d64b9bbc7",
   "metadata": {},
   "source": [
    "Задание №1: Найти велосипед с максимальным временем пробега"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b52b35-44a7-4fb8-9acf-e2933d1250ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат:\n",
      "+-------+--------+\n",
      "|bike_id|     dur|\n",
      "+-------+--------+\n",
      "|    535|36229902|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# Выполнение запроса с использованием DataFrame API\n",
    "result = tripData.groupBy(\"bike_id\").agg(F.sum(\"duration\").alias(\"dur\")) \\\n",
    "                 .orderBy(F.desc(\"dur\")).limit(1)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Результат:\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887a815-86ca-464c-bbda-bb72a76adff1",
   "metadata": {},
   "source": [
    "Задание 2: Найти наибольшее геодезическое расстояние между станциями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27bf7877-ae96-48ee-93dc-e87c79effa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: geopy in ./.local/lib/python3.9/site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in ./.local/lib/python3.9/site-packages (from geopy) (2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc734b9-10c5-48da-8d62-06b6bb1449ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшее геодезическое расстояние между станциями 24 и 36: 9.669526104642657 км\n"
     ]
    }
   ],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "from geopy.distance import geodesic\n",
    "# Выбор необходимых столбцов для расчета расстояния\n",
    "stations_coordinates = stationData.select(\"id\", \"lat\", \"long\").withColumnRenamed(\"lat\", \"lat1\").withColumnRenamed(\"long\", \"long1\")\n",
    "stations_coordinates.createOrReplaceTempView(\"stations_coordinates\")\n",
    "\n",
    "# Кросс-джойн для получения всех возможных комбинаций станций\n",
    "station_combinations = spark.sql(\"\"\"\n",
    "    SELECT a.id as station1, b.id as station2, a.lat1, a.long1, b.lat1 as lat2, b.long1 as long2\n",
    "    FROM stations_coordinates a\n",
    "    CROSS JOIN stations_coordinates b\n",
    "    WHERE a.id < b.id\n",
    "\"\"\")\n",
    "\n",
    "# Функция для вычисления геодезического расстояния\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    coord1 = (lat1, lon1)\n",
    "    coord2 = (lat2, lon2)\n",
    "    return geodesic(coord1, coord2).kilometers\n",
    "\n",
    "# Регистрация функции UDF\n",
    "calculate_distance_udf = spark.udf.register(\"calculate_distance\", calculate_distance)\n",
    "\n",
    "# Вычисление расстояния\n",
    "result = station_combinations.withColumn(\"distance\", calculate_distance_udf(\"lat1\", \"long1\", \"lat2\", \"long2\"))\n",
    "\n",
    "# Нахождение максимального расстояния\n",
    "max_distance = result.select(\"station1\", \"station2\", \"distance\").orderBy(col(\"distance\").desc()).first()\n",
    "\n",
    "print(f\"Наибольшее геодезическое расстояние между станциями {max_distance['station1']} и {max_distance['station2']}: {max_distance['distance']} км\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c906d29e-f499-4edf-838b-e84d42adf42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|                name|    end_station_name|          distance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|       2nd at Folsom|South Van Ness at...|2.3150845505323323|\n",
      "|South Van Ness at...|       2nd at Folsom|2.3150845505323323|\n",
      "+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Определение велосипеда с максимальным временем пробега\n",
    "max_duration_trip = tripData.orderBy(col(\"duration\").desc()).limit(1).select(\"start_station_name\", \"end_station_name\").first()\n",
    "\n",
    "# Фильтрация данных для велосипеда с максимальным временем пробега\n",
    "filtered_joined_station = stationData \\\n",
    "    .filter((col(\"name\") == max_duration_trip.start_station_name) |\n",
    "            (col(\"name\") == max_duration_trip.end_station_name))\n",
    "\n",
    "# Создание нового DataFrame, который содержит расстояние между станциями\n",
    "result_3 = filtered_joined_station.crossJoin(\n",
    "    filtered_joined_station.select(col(\"name\").alias(\"end_station_name\"), col(\"lat\").alias(\"end_lat\"), col(\"long\").alias(\"end_long\"))\n",
    ") \\\n",
    ".withColumn(\"distance\", calculate_distance_udf(col(\"lat\"), col(\"long\"), col(\"end_lat\"), col(\"end_long\"))) \\\n",
    ".select(\"name\", \"end_station_name\", \"distance\") \\\n",
    ".filter((col(\"name\") != col(\"end_station_name\")) & (col(\"distance\") != 0))  # Исключаем строки, где начальная и конечная станции совпадают и расстояние равно 0\n",
    "\n",
    "# Вывод результата\n",
    "result_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc4ea1-5d64-480f-8c2b-1fbb5e40e0cf",
   "metadata": {},
   "source": [
    "Задание 4. Найти количество велосипедов в системе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f9b7f50-057f-40e9-ba6c-5eaf5604e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество велосипедов в системе: 700\n"
     ]
    }
   ],
   "source": [
    "# Подсчет уникальных велосипедов в DataFrame tripData\n",
    "bike_count = tripData.select(\"bike_id\").distinct().count()\n",
    "\n",
    "# Вывод результата\n",
    "print(f\"Количество велосипедов в системе: {bike_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332fa12f-3928-4fcf-b761-f769d87f3c64",
   "metadata": {},
   "source": [
    "Задание 5. Найти пользователей потративших на поездки более 3 часов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d5a85c6-d85f-4ed1-bbb6-9ec2ecf9478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат:\n",
      "+------+------------+\n",
      "|    id|sum_duration|\n",
      "+------+------------+\n",
      "|  6654|       17751|\n",
      "| 22097|       21686|\n",
      "| 22223|       15619|\n",
      "| 30654|       13479|\n",
      "| 34759|       17959|\n",
      "| 43688|       22504|\n",
      "| 88666|       21964|\n",
      "| 88674|       13726|\n",
      "|105536|       19854|\n",
      "|143153|       20649|\n",
      "|146988|       44084|\n",
      "|189310|       21785|\n",
      "|431881|       28377|\n",
      "|431018|       12301|\n",
      "|427387|       12612|\n",
      "|418759|       15526|\n",
      "|418461|       15103|\n",
      "|410754|       16743|\n",
      "|386707|       14313|\n",
      "|305619|       12412|\n",
      "+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Группировка данных по клиентам и суммирование длительности поездок\n",
    "grouped_data = tripData.groupBy(\"id\").agg({\"duration\": \"sum\"}).withColumnRenamed(\"sum(duration)\", \"sum_duration\")\n",
    "\n",
    "# Фильтрация данных для клиентов, потративших на поездки более 3 часов\n",
    "filtered_data = grouped_data.filter(col(\"sum_duration\") > 10800)\n",
    "\n",
    "# Вывод результата\n",
    "print(\"Результат:\")\n",
    "filtered_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "388578e9-f4e4-4b5e-bdd9-9189c2421090",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
